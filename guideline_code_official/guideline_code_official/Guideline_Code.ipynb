{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-23 01:47:01.948379: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-23 01:47:04.943386: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-09-23 01:47:11.505089: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-09-23 01:47:11.505143: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-09-23 01:47:11.505148: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers\n",
    "import cv2\n",
    "import os\n",
    "from imutils import paths\n",
    "import imutils\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "import models\n",
    "from models import SimplePreprocessor, AnimalsDatasetManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn():\n",
    "    model = models.models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3,3), padding='same', activation= 'relu', input_shape=(32,32,3)))\n",
    "    model.add(layers.Conv2D(32, (3,3), padding='same', activation='relu'))\n",
    "    model.add(layers.AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
    "    model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "    model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "    model.add(layers.AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_folder_dict(adir):\n",
    "    sub_folders= [folder for folder in os.listdir(adir)\n",
    "                  if os.path.isdir(os.path.join(adir, folder))]\n",
    "    label_folder_dict= dict()\n",
    "    for folder in sub_folders:\n",
    "        item= {folder: os.path.abspath(os.path.join(adir, folder))}\n",
    "        label_folder_dict.update(item)\n",
    "    return label_folder_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datasets']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../../train_dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_folder_dict= create_label_folder_dict(\"../../train_dataset/datasets/Animals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dogs 501\n",
      "Processed 100/500\n",
      "Processed 200/500\n",
      "Processed 300/500\n",
      "Processed 400/500\n",
      "Processed 500/500\n",
      "cows 500\n",
      "Processed 100/500\n",
      "Processed 200/500\n",
      "Processed 300/500\n",
      "Processed 400/500\n",
      "Processed 500/500\n",
      "spiders 500\n",
      "Processed 100/500\n",
      "Processed 200/500\n",
      "Processed 300/500\n",
      "Processed 400/500\n",
      "Processed 500/500\n",
      "fishes 500\n",
      "Processed 100/500\n",
      "Processed 200/500\n",
      "Processed 300/500\n",
      "Processed 400/500\n",
      "Processed 500/500\n",
      "butterfiles 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 200/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 300/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 400/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 500/500\n",
      "horses 500\n",
      "Processed 100/500\n",
      "Processed 200/500\n",
      "Processed 300/500\n",
      "Processed 400/500\n",
      "Processed 500/500\n",
      "chickens 500\n",
      "Processed 100/500\n",
      "Processed 200/500\n",
      "Processed 300/500\n",
      "Processed 400/500\n",
      "Processed 500/500\n",
      "elephants 500\n",
      "Processed 100/500\n",
      "Processed 200/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 300/500\n",
      "Processed 400/500\n",
      "Processed 500/500\n",
      "lions 500\n",
      "Processed 100/500\n",
      "Processed 200/500\n",
      "Processed 300/500\n",
      "Processed 400/500\n",
      "Processed 500/500\n",
      "cats 501\n",
      "Processed 100/500\n",
      "Processed 200/500\n",
      "Processed 300/500\n",
      "Processed 400/500\n",
      "Processed 500/500\n"
     ]
    }
   ],
   "source": [
    "sp = SimplePreprocessor(width=32, height=32)\n",
    "data_manager = AnimalsDatasetManager([sp])\n",
    "data_manager.load(label_folder_dict, verbose=100)\n",
    "data_manager.process_data_label()\n",
    "data_manager.train_valid_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-23 01:50:23.459223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-23 01:50:24.221795: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ayden/miniconda3/envs/deep_learning/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2022-09-23 01:50:24.221817: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-09-23 01:50:24.245294: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = build_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4000 samples, validate on 500 samples\n",
      "Epoch 1/30\n",
      "4000/4000 [==============================] - 6s 2ms/sample - loss: 2.0673 - accuracy: 0.2515 - val_loss: 1.8944 - val_accuracy: 0.3480\n",
      "Epoch 2/30\n",
      "4000/4000 [==============================] - 6s 1ms/sample - loss: 1.7161 - accuracy: 0.4000 - val_loss: 1.7054 - val_accuracy: 0.4080\n",
      "Epoch 3/30\n",
      "4000/4000 [==============================] - 6s 1ms/sample - loss: 1.5653 - accuracy: 0.4570 - val_loss: 1.7054 - val_accuracy: 0.4580\n",
      "Epoch 4/30\n",
      "4000/4000 [==============================] - 6s 1ms/sample - loss: 1.4145 - accuracy: 0.5048 - val_loss: 1.6883 - val_accuracy: 0.4800\n",
      "Epoch 5/30\n",
      "4000/4000 [==============================] - 6s 2ms/sample - loss: 1.2742 - accuracy: 0.5545 - val_loss: 1.6076 - val_accuracy: 0.5080\n",
      "Epoch 6/30\n",
      "4000/4000 [==============================] - 6s 2ms/sample - loss: 1.1257 - accuracy: 0.6227 - val_loss: 1.5366 - val_accuracy: 0.5380\n",
      "Epoch 7/30\n",
      "4000/4000 [==============================] - 6s 1ms/sample - loss: 1.0085 - accuracy: 0.6565 - val_loss: 1.4795 - val_accuracy: 0.5600\n",
      "Epoch 8/30\n",
      "4000/4000 [==============================] - 6s 1ms/sample - loss: 0.8776 - accuracy: 0.6990 - val_loss: 1.5711 - val_accuracy: 0.5220\n",
      "Epoch 9/30\n",
      "4000/4000 [==============================] - 6s 1ms/sample - loss: 0.7553 - accuracy: 0.7415 - val_loss: 1.7468 - val_accuracy: 0.5220\n",
      "Epoch 10/30\n",
      "4000/4000 [==============================] - 6s 1ms/sample - loss: 0.6346 - accuracy: 0.7837 - val_loss: 1.6219 - val_accuracy: 0.5460\n",
      "Epoch 11/30\n",
      "4000/4000 [==============================] - 6s 1ms/sample - loss: 0.5351 - accuracy: 0.8198 - val_loss: 1.8574 - val_accuracy: 0.5320\n",
      "Epoch 12/30\n",
      "4000/4000 [==============================] - 6s 1ms/sample - loss: 0.4154 - accuracy: 0.8547 - val_loss: 1.9652 - val_accuracy: 0.5680\n",
      "Epoch 13/30\n",
      "4000/4000 [==============================] - 6s 1ms/sample - loss: 0.3530 - accuracy: 0.8813 - val_loss: 2.2911 - val_accuracy: 0.5300\n",
      "Epoch 14/30\n",
      "4000/4000 [==============================] - 6s 1ms/sample - loss: 0.2618 - accuracy: 0.9137 - val_loss: 2.3868 - val_accuracy: 0.5400\n",
      "Epoch 15/30\n",
      "4000/4000 [==============================] - 6s 1ms/sample - loss: 0.1857 - accuracy: 0.9417 - val_loss: 2.7041 - val_accuracy: 0.5340\n",
      "Epoch 16/30\n",
      "4000/4000 [==============================] - 6s 1ms/sample - loss: 0.1684 - accuracy: 0.9410 - val_loss: 2.9890 - val_accuracy: 0.5220\n",
      "Epoch 17/30\n",
      "4000/4000 [==============================] - 6s 1ms/sample - loss: 0.1104 - accuracy: 0.9668 - val_loss: 3.1812 - val_accuracy: 0.5360\n",
      "Epoch 18/30\n",
      "4000/4000 [==============================] - 6s 1ms/sample - loss: 0.0830 - accuracy: 0.9785 - val_loss: 3.5518 - val_accuracy: 0.5360\n",
      "Epoch 19/30\n",
      "4000/4000 [==============================] - 6s 1ms/sample - loss: 0.0945 - accuracy: 0.9712 - val_loss: 3.9940 - val_accuracy: 0.5100\n",
      "Epoch 20/30\n",
      "4000/4000 [==============================] - 6s 1ms/sample - loss: 0.1116 - accuracy: 0.9668 - val_loss: 3.8271 - val_accuracy: 0.5160\n",
      "Epoch 21/30\n",
      "4000/4000 [==============================] - 6s 1ms/sample - loss: 0.1123 - accuracy: 0.9635 - val_loss: 3.4579 - val_accuracy: 0.5380\n",
      "Epoch 22/30\n",
      "4000/4000 [==============================] - 6s 1ms/sample - loss: 0.0429 - accuracy: 0.9887 - val_loss: 3.8406 - val_accuracy: 0.5460\n",
      "Epoch 23/30\n",
      "4000/4000 [==============================] - 6s 1ms/sample - loss: 0.0616 - accuracy: 0.9812 - val_loss: 4.3390 - val_accuracy: 0.5220\n",
      "Epoch 24/30\n",
      "4000/4000 [==============================] - 6s 1ms/sample - loss: 0.0949 - accuracy: 0.9695 - val_loss: 3.8391 - val_accuracy: 0.5340\n",
      "Epoch 25/30\n",
      "4000/4000 [==============================] - 6s 1ms/sample - loss: 0.0741 - accuracy: 0.9780 - val_loss: 4.4488 - val_accuracy: 0.5420\n",
      "Epoch 26/30\n",
      "4000/4000 [==============================] - 6s 2ms/sample - loss: 0.0785 - accuracy: 0.9730 - val_loss: 4.0788 - val_accuracy: 0.5180\n",
      "Epoch 27/30\n",
      "4000/4000 [==============================] - 6s 2ms/sample - loss: 0.0593 - accuracy: 0.9795 - val_loss: 4.1033 - val_accuracy: 0.5100\n",
      "Epoch 28/30\n",
      "4000/4000 [==============================] - 6s 1ms/sample - loss: 0.0363 - accuracy: 0.9893 - val_loss: 4.5260 - val_accuracy: 0.5340\n",
      "Epoch 29/30\n",
      "4000/4000 [==============================] - 6s 1ms/sample - loss: 0.0446 - accuracy: 0.9893 - val_loss: 4.1943 - val_accuracy: 0.5560\n",
      "Epoch 30/30\n",
      "4000/4000 [==============================] - 6s 1ms/sample - loss: 0.0156 - accuracy: 0.9958 - val_loss: 4.3759 - val_accuracy: 0.5420\n"
     ]
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate= 0.001)\n",
    "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x = data_manager.X_train, y = data_manager.y_train, validation_data = (data_manager.X_valid, data_manager.y_valid), epochs = 30, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['butterfiles', 'cats', 'chickens', 'cows', 'dogs', 'elephants',\n",
       "       'fishes', 'horses', 'lions', 'spiders'], dtype='<U11')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_manager.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_labels = ['butterfly', 'cat', 'chicken', 'cow', 'dog', 'elephant', 'fish', 'horse', 'lion', 'spider']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list_images() missing 1 required positional argument: 'basePath'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpaths\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: list_images() missing 1 required positional argument: 'basePath'"
     ]
    }
   ],
   "source": [
    "paths.list_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array\n",
    "\n",
    "def load_test_set(folder):\n",
    "    image_paths = sorted(list(paths.list_images(folder)))\n",
    "    test_data = []\n",
    "    for i, image_path in enumerate(image_paths):\n",
    "        img = Image.open(image_path).convert(\"RGB\") #load_img(image_path)\n",
    "        img = img.resize((32, 32), Image.ANTIALIAS)\n",
    "        x = img_to_array(img)\n",
    "        test_data.append(x)\n",
    "        if i+1 % 500 ==0:\n",
    "            print(\"Loaded {} images\".format(i+1))\n",
    "    test_data = np.asarray(test_data)\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9465/1344258102.py:8: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  img = img.resize((32, 32), Image.ANTIALIAS)\n"
     ]
    }
   ],
   "source": [
    "test_data = load_test_set(\"../../test_dataset/official_test_aug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape: (23098, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Test shape: {}\".format(test_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "722/722 [==============================] - 6s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(test_data, batch_size= 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23098, 10)\n",
      "[[2.64762896e-25 5.05220331e-03 1.63038578e-06 2.04255935e-11\n",
      "  5.45628518e-06 2.48891661e-06 2.85853594e-06 1.28714652e-13\n",
      "  6.16673827e-01 3.78261566e-01]\n",
      " [2.42036382e-16 2.80998275e-03 1.40502552e-05 3.87476629e-09\n",
      "  1.41397453e-04 1.85277931e-05 5.19882524e-05 3.46318352e-09\n",
      "  4.28631231e-02 9.54100788e-01]\n",
      " [3.03096943e-17 1.00692578e-01 2.19915783e-05 1.55754343e-08\n",
      "  7.62694108e-05 4.47955681e-05 4.94096366e-06 7.27642335e-10\n",
      "  6.73103109e-02 8.31849039e-01]\n",
      " [2.01050025e-15 9.21775959e-03 4.84983751e-08 2.61488566e-07\n",
      "  2.42336202e-04 2.67081923e-05 1.14385348e-05 1.28847705e-06\n",
      "  2.36071974e-01 7.54428148e-01]\n",
      " [2.12229789e-10 2.31914464e-02 4.09421325e-02 1.81923178e-06\n",
      "  2.66104209e-04 4.47669346e-03 1.77247392e-04 5.01193433e-08\n",
      "  2.01459274e-01 7.29485154e-01]\n",
      " [5.42286121e-15 1.23785166e-02 1.27323892e-06 1.22428490e-09\n",
      "  5.46509546e-06 8.57289124e-05 1.12258305e-04 9.68348735e-10\n",
      "  4.38818246e-01 5.48598647e-01]\n",
      " [7.91092560e-13 5.17686680e-02 1.17209100e-04 4.41720249e-06\n",
      "  2.72780628e-04 8.83101966e-05 2.39648041e-04 5.24970403e-07\n",
      "  6.04967028e-02 8.87011707e-01]\n",
      " [4.02840902e-16 4.81716901e-01 8.31512459e-09 1.48927999e-08\n",
      "  8.74289952e-04 3.12369457e-06 1.09111279e-05 1.68254548e-08\n",
      "  5.96387952e-04 5.16798437e-01]\n",
      " [8.57055161e-21 6.96116760e-02 9.07131016e-06 7.53421681e-09\n",
      "  9.27316876e-07 1.30084277e-06 1.58780909e-04 6.39334097e-09\n",
      "  7.58714259e-01 1.71504021e-01]\n",
      " [3.87611018e-14 7.13364745e-04 3.02586523e-05 3.29780363e-07\n",
      "  2.81285401e-02 1.31601788e-04 2.17106921e-04 7.53624885e-10\n",
      "  2.14069732e-03 9.68638122e-01]\n",
      " [1.38490755e-18 1.43548414e-01 3.43803066e-07 2.01727496e-10\n",
      "  1.61156919e-07 5.15940201e-07 7.11230598e-07 7.47854209e-12\n",
      "  9.10639316e-02 7.65385985e-01]\n",
      " [9.81543824e-20 2.08794116e-03 1.38098740e-05 7.93789123e-09\n",
      "  7.49090702e-07 1.74921965e-07 1.09832126e-06 4.55631409e-12\n",
      "  9.81403589e-01 1.64926015e-02]\n",
      " [4.07741078e-15 8.11282843e-02 5.51242252e-08 1.08429333e-06\n",
      "  2.50305457e-04 1.04853216e-05 2.56327534e-04 7.51264011e-08\n",
      "  3.97888184e-01 5.20465136e-01]\n",
      " [1.19837815e-20 6.33219082e-04 9.98894620e-07 5.82720608e-11\n",
      "  5.09691404e-07 1.33769413e-06 1.91113504e-05 8.18512480e-11\n",
      "  8.58459294e-01 1.40885487e-01]\n",
      " [4.84827601e-21 7.86058838e-04 4.38865345e-06 3.46444584e-09\n",
      "  1.84118824e-06 1.45125796e-07 6.78489926e-07 5.51821991e-11\n",
      "  7.90276110e-01 2.08930761e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(preds.shape)\n",
    "print(preds[0:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 9 9 9 9 9 9 9 8 9 9 8 9 8 8]\n"
     ]
    }
   ],
   "source": [
    "num_predicted_labels = np.argmax(preds, axis=1)\n",
    "print(num_predicted_labels[0:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lion', 'spider', 'spider', 'spider', 'spider', 'spider', 'spider', 'spider', 'lion', 'spider', 'spider', 'lion', 'spider', 'lion', 'lion']\n"
     ]
    }
   ],
   "source": [
    "cat_predicted_labels = [categorical_labels[num_predicted_labels[i]] for i in range(len(num_predicted_labels))]\n",
    "print(cat_predicted_labels[0:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_solution():\n",
    "    header= ['ID', 'Label']\n",
    "    with open('my_solution.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        # write the header\n",
    "        writer.writerow(header)\n",
    "        data = []\n",
    "        for i in range(len(cat_predicted_labels)):\n",
    "            data.append([str(i), cat_predicted_labels[i]])\n",
    "        writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now can submit the csv file `my_solution.csv` to the Kaggle competition."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('deep_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "744d38de6d85aac356f38ea46202bc135fd7f6bffbfa19cc48ec10c4285a4206"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
